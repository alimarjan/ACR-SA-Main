{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ed4369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b547f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNNING_ON_KAGGLE = True\n",
    "if RUNNING_ON_KAGGLE:\n",
    "    def spell(word):\n",
    "        return word\n",
    "else:\n",
    "    from autocorrect import Speller\n",
    "    spell = Speller(lang='en')\n",
    "    spell('horse')\n",
    "def get_known_words(word_embeddings_file):\n",
    "    words = set()\n",
    "    with open(word_embeddings_file, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.rstrip().rsplit(' ')\n",
    "            words.add(values[0].lower())\n",
    "    return words\n",
    "\n",
    "\n",
    "EMBEDDING_FILE = 'F:/glove/glove.840B.300d.txt'\n",
    "if RUNNING_ON_KAGGLE:\n",
    "    words = set()\n",
    "else:\n",
    "    words = get_known_words(EMBEDDING_FILE)\n",
    "\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "\n",
    "def spell_check(chunk):\n",
    "    fixed_rows = []\n",
    "    for i,row in chunk.iterrows():\n",
    "        fxd_words = []\n",
    "        comment = row['comment_text'].lower()\n",
    "        comment = re.sub('[^a-zA-Z ]+', '', comment)\n",
    "        for w in comment.split():\n",
    "            if w is None:\n",
    "                continue\n",
    "            if w in words or len(w) > 24:\n",
    "                fxd_words.append(w)\n",
    "            else:\n",
    "                fxd_words.append(spell(w).lower())\n",
    "        sp_comment = ' '.join(fxd_words)\n",
    "        fixed_rows.append((row[0],sp_comment))\n",
    "    return fixed_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ed6b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "urlfil=\"F:/dataset/US airline-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa48ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROC_COUNT = cpu_count()\n",
    "CHUNK_SIZE = 1024\n",
    "pool = Pool(PROC_COUNT)\n",
    "for set_name in ['US-Airline']:\n",
    "    source = pd.read_csv(urlfil+'US-Airline.csv')\n",
    "    source['text'] = source['text'].astype(str)\n",
    "    result = source.copy()\n",
    "    fixed_rows = pool.map(spell_check, chunker(source, CHUNK_SIZE))\n",
    "    for fxd_row in fixed_rows:\n",
    "        for index, fixed_comment in fxd_row:\n",
    "            data=result._set_value(index, 'text', fixed_comment)\n",
    "    if RUNNING_ON_KAGGLE:\n",
    "        print(result)\n",
    "    else:\n",
    "        data.to_csv(urlfil+'dataset.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
